{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export needed libraries\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tnrange\n",
    "from oger.ctrl.router import Router, PipelineServer\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xml(name): #split xml for small chunks to annotate\n",
    "    context = ET.iterparse(name, events=('end', ))\n",
    "    folder = str(name).replace('.xml', '').replace('data/', '')\n",
    "    os.mkdir(folder)\n",
    "    os.mkdir(folder +'/xml')\n",
    "    index = 0\n",
    "    for event, elem in context:\n",
    "        if elem.tag == 'PubmedArticle':\n",
    "            index += 1\n",
    "            filename = format(str(index) + \".xml\")\n",
    "            with open(folder + '/xml/' + filename, 'wb') as f:\n",
    "                f.write(ET.tostring(elem))            \n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(fname):\n",
    "    file = ET.parse(str(fname)).getroot()\n",
    "    year = []\n",
    "    for row in file.iter('Year'): #year completed\n",
    "        year.append(row.text)\n",
    "    pmid = []\n",
    "    for row in file.iter('PMID'): #pubmed id\n",
    "        pmid.append(row.text)\n",
    "    jt = []\n",
    "    for row in file.iter('Title'): #journal title\n",
    "        jt.append(row.text)\n",
    "    at = []\n",
    "    for row in file.iter('ArticleTitle'): #article title    \n",
    "        at.append(row.text)\n",
    "    \n",
    "    text_list = []\n",
    "    for row in file.iter('Abstract'): #abstract info\n",
    "        for text_fragment in row.itertext():\n",
    "            text_list.append(text_fragment)\n",
    "    if len(text_list) > 0:\n",
    "        labstr = ''.join(text_list).strip()\n",
    "    else:\n",
    "        labstr = 'nan'\n",
    "      \n",
    "    authors = []\n",
    "    lname = [] #LastName\n",
    "    fname = [] #ForeName\n",
    "    for row in file.iter('LastName'): #last name\n",
    "        lname.append(row.text)\n",
    "    for row in file.iter('ForeName'): #first name\n",
    "        fname.append(row.text)\n",
    "    \n",
    "    num = min(len(lname), len(fname))\n",
    "    for i in range(num):\n",
    "        author = str(lname[i]) + ' ' + str(fname[i])\n",
    "        authors.append(author)\n",
    "    lauth = ', '.join(authors)\n",
    "    #get mails\n",
    "    maill = []\n",
    "    uni = []\n",
    "    for row in file.iter('Author'): \n",
    "        auth = []\n",
    "        for r in row.iter('LastName'):\n",
    "            auth.append(r.text)\n",
    "        for r in row.iter('ForeName'):\n",
    "            auth.append(r.text)\n",
    "\n",
    "        with_mails = []\n",
    "        for r in row.iter('Affiliation'):\n",
    "            with_mails.append(r.text)\n",
    "            uni.append(str(' '.join(auth) + ' (' + r.text + ')'))\n",
    "            \n",
    "        mail_list = []\n",
    "        if len(with_mails) > 0:\n",
    "            for i in range(len(with_mails)):\n",
    "                look = re.findall('@', str(with_mails[i]))\n",
    "                if len(look) > 0:\n",
    "                    #print(with_mails[i])\n",
    "                    look2 = with_mails[i]\n",
    "                    mail = re.findall('\\S{,100}@\\S{,100}', look2)[0]\n",
    "                    mail_list.append(mail)   \n",
    "        if len(mail_list) > 0:\n",
    "            au = str(mail_list[0]) + str(' (' + ' '.join(auth) + ')')\n",
    "        else:\n",
    "            au = 'nan'\n",
    "        if au != 'nan':\n",
    "            maill.append(au)        \n",
    "    if len(maill) > 0:\n",
    "        maill = ', '.join(maill)  \n",
    "    else:\n",
    "        maill = 'nan'\n",
    "    uni = ', '.join(uni)\n",
    "    new_row = {'Year': [year[1]], 'PMID': [pmid[0]], 'JTitle': [jt[0]], 'ATitle': [at[0]],\n",
    "               'Abstract': [labstr], 'Authors': [lauth], 'EMails': [maill], 'Affilation': [uni]}\n",
    "    nr = pd.DataFrame(new_row) \n",
    "    return nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = split_xml('data/pubmed20n1017.xml') #path to needed xml file\n",
    "files = os.listdir(path = str(folder) + str('/xml')) #list of files with needed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d6c613d711424f9dc579eefa65f47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#here we get dataframe for future processing\n",
    "df = pd.DataFrame()\n",
    "for i in tnrange(len(files)):\n",
    "    el = files[i]    \n",
    "    fname = str(folder) + '/xml/' + str(el)\n",
    "    if str(type(fname)) == '<class \\'str\\'>':\n",
    "        row = get_article_info(fname)\n",
    "        df = df.append(row)\n",
    "        df.index = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting file to pubtator format for annotation\n",
    "\n",
    "def to_pubtator_format(df):\n",
    "    num = 1\n",
    "    num2 = 0\n",
    "    if not os.path.exists(folder +'/annotate'): # создаем ее, если не существует\n",
    "        os.makedirs(folder +'/annotate')\n",
    "    for i in range(len(df)):\n",
    "        if num > num2:\n",
    "            with open(folder + '/annotate/test_' + str(num) + '.PubTator', 'w+') as f:\n",
    "                f.close()\n",
    "            num2 += 1\n",
    "\n",
    "        s1 = str('\\n' + str(df.loc[i, 'PMID']) + '|t|' + str(df.loc[i, 'ATitle']).replace('\\n', ''))\n",
    "        s2 = str('\\n' + str(df.loc[i, 'PMID']) + '|a|' + str(df.loc[i, 'Abstract']).replace('\\n', '') + '\\n\\n')\n",
    "\n",
    "        with open(folder + '/annotate/test_' + str(num) + '.PubTator', 'a') as f:\n",
    "            f.write(s1)\n",
    "            f.write(s2)\n",
    "            f.close()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            num += 1\n",
    "    return('Convering to PubTator format is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubtator_annotator(folder):\n",
    "    input_path = folder + '/annotate/' \n",
    "    output_path = folder + '/annotate_res/'           \n",
    "    if not os.path.exists(output_path): \n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    fls = os.listdir(input_path) \n",
    "    fls = [row for row in fls if '.PubTator' in row] \n",
    "    print(fls)\n",
    "    terms_list = 'needed_info/medchem_terms_norm_v2.txt' # path to file with drug discovery terms\n",
    "    conf = Router(termlist_path=terms_list) # load terms\n",
    "    pl = PipelineServer(conf) # create annotator\n",
    "    \n",
    "    # Going in cycle through files\n",
    "    for k,fl in enumerate(fls):\n",
    "        annotations = []\n",
    "        print('started %d file. Total files: %d'%(k+1,len(fls)))\n",
    "\n",
    "        doc = pl.load_one(input_path+fl, 'pubtator') # loading the file to annotator\n",
    "        pl.process(doc) # annotation\n",
    "        for row in doc: # going through each article\n",
    "            for entity in row.iter_entities(): # through annotation from article\n",
    "                annotations.append([row.id_, entity.info[3], entity.info[1]]) # [id article, id term, name term]\n",
    "\n",
    "        #write the result into file (separator - \"\\t\")\n",
    "        with io.open(output_path+fl,'w',encoding = 'utf-8') as f:\n",
    "            for row in annotations:\n",
    "                f.write('\\t'.join(row)+'\\n')\n",
    "                \n",
    "    return('Checked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(folder):  \n",
    "    fls = os.listdir(path = folder + '/annotate_res')\n",
    "    fls = [row for row in fls if '.PubTator' in row]\n",
    "    \n",
    "    for i in range(len(fls)):\n",
    "        file = fls[i]\n",
    "        with open(folder +'/annotate_res/'+file, 'r') as f:\n",
    "            lines = f.read()\n",
    "        lines = lines.split('\\n')\n",
    "    \n",
    "    keys = pd.DataFrame()\n",
    "    for i in range(len(lines)):\n",
    "        elem = lines[i]\n",
    "        elem = elem.split('\\t')\n",
    "        #print(elem)\n",
    "        if len(elem) == 3:\n",
    "            pid = elem[0]\n",
    "            nw = elem[2]\n",
    "            rw = {'PMID': [pid], 'Key': [nw]}\n",
    "            ow = pd.DataFrame(rw)\n",
    "            keys = keys.append(ow)\n",
    "            keys.index = np.arange(len(keys))\n",
    "\n",
    "    valid_ids = []\n",
    "    for i in range(len(keys)):\n",
    "        if keys.loc[i, 'PMID'] not in valid_ids:\n",
    "            valid_ids.append(keys.loc[i, 'PMID'])\n",
    "\n",
    "    unik = pd.DataFrame()\n",
    "    for i in range(len(valid_ids)):\n",
    "        vid = valid_ids[i]\n",
    "        q = keys[keys['PMID'] == vid]\n",
    "        q.index = np.arange(len(q))\n",
    "        keyss = str()\n",
    "        for i in range(len(q)):\n",
    "            if keyss == '':\n",
    "                keyss = q.loc[i, 'Key']\n",
    "            else:\n",
    "                keyss = keyss + ', ' + q.loc[i, 'Key']\n",
    "        row = {'PMID': [vid], 'Keys': [keyss]}\n",
    "        row = pd.DataFrame(row)\n",
    "        unik = unik.append(row)\n",
    "        unik.index = np.arange(len(unik))\n",
    "\n",
    "    return unik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_10.PubTator', 'test_11.PubTator', 'test_24.PubTator', 'test_25.PubTator', 'test_4.PubTator', 'test_5.PubTator', 'test_9.PubTator', 'test_8.PubTator', 'test_29.PubTator', 'test_28.PubTator', 'test_17.PubTator', 'test_16.PubTator', 'test_23.PubTator', 'test_22.PubTator', 'test_3.PubTator', 'test_2.PubTator', 'test_30.PubTator', 'test_31.PubTator', 'test_27.PubTator', 'test_26.PubTator', 'test_7.PubTator', 'test_6.PubTator', 'test_19.PubTator', 'test_18.PubTator', 'test_13.PubTator', 'test_12.PubTator', 'test_20.PubTator', 'test_21.PubTator', 'test_1.PubTator', 'test_14.PubTator', 'test_15.PubTator']\n",
      "started 1 file. Total files: 31\n",
      "started 2 file. Total files: 31\n",
      "started 3 file. Total files: 31\n",
      "started 4 file. Total files: 31\n",
      "started 5 file. Total files: 31\n",
      "started 6 file. Total files: 31\n",
      "started 7 file. Total files: 31\n",
      "started 8 file. Total files: 31\n",
      "started 9 file. Total files: 31\n",
      "started 10 file. Total files: 31\n",
      "started 11 file. Total files: 31\n",
      "started 12 file. Total files: 31\n",
      "started 13 file. Total files: 31\n",
      "started 14 file. Total files: 31\n",
      "started 15 file. Total files: 31\n",
      "started 16 file. Total files: 31\n",
      "started 17 file. Total files: 31\n",
      "started 18 file. Total files: 31\n",
      "started 19 file. Total files: 31\n",
      "started 20 file. Total files: 31\n",
      "started 21 file. Total files: 31\n",
      "started 22 file. Total files: 31\n",
      "started 23 file. Total files: 31\n",
      "started 24 file. Total files: 31\n",
      "started 25 file. Total files: 31\n",
      "started 26 file. Total files: 31\n",
      "started 27 file. Total files: 31\n",
      "started 28 file. Total files: 31\n",
      "started 29 file. Total files: 31\n",
      "started 30 file. Total files: 31\n",
      "started 31 file. Total files: 31\n"
     ]
    }
   ],
   "source": [
    "to_pubtator_format(df)\n",
    "pubtator_annotator(folder)\n",
    "unik = get_keys(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdefda8aeda42fbacf795400727e5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=283), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['Valid'] = 0\n",
    "df['Keys'] = 'NaN'\n",
    "for i in tnrange(len(unik)):\n",
    "    if len(df[df['PMID'] == unik.loc[i, 'PMID']]) != 0:\n",
    "        for j in range(len(df)):\n",
    "            if str(df.loc[j, 'PMID']) == str(unik.loc[i, 'PMID']):\n",
    "                df.at[j, 'Valid'] = 1\n",
    "                df.at[j, 'Keys'] = str(unik.loc[i, 'Keys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('nan')\n",
    "res1 = df['Valid'] == 1\n",
    "res2 = df['EMails'] != 'nan'\n",
    "f_df = df[res1 & res2]\n",
    "f_df.to_csv(folder + '/' + str(folder) + '_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
